## Functional Requirements
The organization intends to use its own infrastructure to maintain control over user data, AI inference costs, and system latency.

To support this initiative, they will acquire an AI workstation costing around $10,000–$15,000, equipped with high-performance GPUs for on-premise inference. The system will serve 300 students in Dubai, ensuring low-latency access to GenAI-powered study activities.

## Assumptions
An open-source model such as DeepSeek R1, Llama 2, Mistral 7B, or IBM Granite will be selected based on efficiency and hardware compatibility. The chosen language model must be optimized to operate within the allocated AI workstation resources.

A dedicated server will be deployed either in the office or in the company’s private cloud infrastructure, ensuring data security and cost efficiency.

## Data Strategy
To mitigate intellectual property risks, the organization will procure licensed content or use legally compliant, copyright-free datasets.

Additionally, data ingestion will focus on structured, high-quality educational material to enhance model accuracy and relevance.

## Considerations
Several open-source models are being evaluated, including Llama 2 (Meta), Mistral 7B, and IBM Granite, which offer scalability, efficiency, and traceable training data for legal compliance.

The final model selection will depend on performance benchmarks, deployment feasibility within the given hardware, and integration with the organization's RAG-based study system.